model_name:
  desc: HuggingFace language model to use, or "mock" for testing
  value: "EleutherAI/gpt-neo-125M"
reward_model_name:
  desc: HuggingFace reward model to use, or "mock" for testing
  value: "OpenAssistant/reward-model-deberta-v3-base"
log_with:
  desc: "The logger to use"
  value: "wandb"
learning_rate:
  desc: "The learning rate"
  value: 0.0000141 # 1.41e-5
mini_batch_size:
  desc: "The mini-batch size"
  value: 2
batch_size:
  desc: "The batch size" # default 256 in og code
  value: 4
gradient_accumulation_steps:
  desc: "The number of gradient accumulation steps"
  value: 1
max_new_tokens:
  desc: "The maximum number of new tokens to generate per prompt"
  value: 64
max_prompt_char_length:
  desc: "The maximum number of characters in a prompt"
  value: 1024
dataset_names:
  desc: The list of datasets to use for prompts. See src/superhf/data.py for available datasets.
  value: ["anthropic-red-team", "anthropic-helpful-base", "anthropic-harmless-base", "openai/webgpt_comparisons"]
debug_max_prompts:
  desc: "The maximum number of prompts to use for debugging. 0 to use all prompts."
  value: 124